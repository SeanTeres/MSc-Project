{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user-pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchxrayvision\\utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, ConcatDataset, WeightedRandomSampler, Subset, DataLoader\n",
    "import os\n",
    "import torchxrayvision as xrv\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import pydicom\n",
    "from torchxrayvision.datasets import XRayCenterCrop\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, classification_report, confusion_matrix\n",
    "import helpers, train_utils, classes\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_dir_1 = 'C:/Users/user-pc/Masters/MSc - Project/MBOD_Datasets/Dataset 1'\n",
    "metadata_1 = pd.read_excel('C:/Users/user-pc/Masters/MSc - Project/MBOD_Datasets/Dataset 1/FileDatabaseWithRadiology.xlsx')\n",
    "dicom_dir_2 = 'C:/Users/user-pc/Masters/MSc - Project/MBOD_Datasets/Dataset 2'\n",
    "metadata_2 = pd.read_excel('C:/Users/user-pc/Masters/MSc - Project/MBOD_Datasets/Dataset 2/Database_Training-2024.08.28.xlsx')\n",
    "\n",
    "d1 = classes.DICOMDataset1(dicom_dir=dicom_dir_1, metadata_df=metadata_1, target_size=224) \n",
    "d2 = classes.DICOMDataset2(dicom_dir=dicom_dir_2, metadata_df=metadata_2, target_size=224)\n",
    "\n",
    "# Split datasets and store indices\n",
    "train_indices_d1, val_indices_d1, test_indices_d1 = helpers.split_dataset(d1)\n",
    "train_indices_d2, val_indices_d2, test_indices_d2 = helpers.split_dataset(d2)\n",
    "\n",
    "# Save indices for later use\n",
    "split_indices = {\n",
    "    'd1': {'train': train_indices_d1, 'val': val_indices_d1, 'test': test_indices_d1},\n",
    "    'd2': {'train': train_indices_d2, 'val': val_indices_d2, 'test': test_indices_d2}\n",
    "}\n",
    "\n",
    "label = 'Profusion'\n",
    "d1.set_target(target_label=label, target_size=224)\n",
    "d2.set_target(target_label=label, target_size=224)\n",
    "\n",
    "train_d1 = Subset(d1, train_indices_d1)\n",
    "val_d1 = Subset(d1, val_indices_d1)\n",
    "test_d1 = Subset(d1, test_indices_d1)\n",
    "\n",
    "train_d2 = Subset(d2, train_indices_d2)\n",
    "val_d2 = Subset(d2, val_indices_d2)\n",
    "test_d2 = Subset(d2, test_indices_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler: <torch.utils.data.sampler.WeightedRandomSampler object at 0x000001AAF3B5DD50>\n",
      "Sampler: <torch.utils.data.sampler.WeightedRandomSampler object at 0x000001AAF3E85F90>\n"
     ]
    }
   ],
   "source": [
    "def create_weighted_sampler(dataset, target_label):\n",
    "    # Calculate class weights\n",
    "    class_counts = np.bincount([label for _, label in dataset])\n",
    "    class_weights = 1. / class_counts\n",
    "    sample_weights = [class_weights[label] for _, label in dataset]\n",
    "\n",
    "    # Create a weighted sampler\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "    return sampler\n",
    "\n",
    "# Create the base datasets\n",
    "train_d1 = Subset(d1, train_indices_d1)\n",
    "train_d2 = Subset(d2, train_indices_d2)\n",
    "\n",
    "# Define augmentations\n",
    "augmentations_list = [\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "]\n",
    "\n",
    "# Create augmented datasets\n",
    "augmented_train_d1 = classes.AugmentedDataset(base_dataset=train_d1, augmentations_list=augmentations_list)\n",
    "augmented_train_d2 = classes.AugmentedDataset(base_dataset=train_d2, augmentations_list=augmentations_list)\n",
    "\n",
    "    # Create dataloaders\n",
    "train_loader_d1, train_aug_loader_d1, val_loader_d1, test_loader_d1 = helpers.create_dataloaders(\n",
    "    train_d1, augmented_train_d1, val_d1, test_d1, batch_size=32, oversam=True, target=label\n",
    ")\n",
    "\n",
    "train_loader_d2, train_aug_loader_d2, val_loader_d2, test_loader_d2 = helpers.create_dataloaders(\n",
    "    train_d2, augmented_train_d2, val_d2, test_d2, batch_size=32, oversam=True, target=label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\").to(device)\n",
    "model.classifier = classes.BaseClassifier(in_features=1024\n",
    "                                          \n",
    "                                          )\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
